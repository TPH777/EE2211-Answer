{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86992994-cfc1-43ea-a017-47963025eda4",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> Question 6 (continued from Q3 of Tutorial 2): </span>\n",
    "\n",
    "Get the data set “from sklearn.datasets import load_iris”. Use Python to perform the following\n",
    "tasks.\n",
    "1. Split the database into two sets: 74% of samples for training, and 26% of samples for testing. Hint: you might\n",
    "want to utilize from sklearn.model_selection import train_test_split for the splitting.\n",
    "2. Construct the target output using one-hot encoding.\n",
    "3. Perform a linear regression for classification (without inclusion of ridge, utilizing one-hot encoding for the\n",
    "learning target) and compute the number of test samples that are classified correctly.\n",
    "4. Using the same training and test sets as in above, perform a 2nd order polynomial regression for classification\n",
    "(again, without inclusion of ridge, utilizing one-hot encoding for the learning target) and compute the number\n",
    "of test samples that are classified correctly. Hint: you might want to use from\n",
    "sklearn.preprocessing import PolynomialFeatures for generation of the polynomial\n",
    "matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3267cb93-196a-48ce-b3a1-dfd200c23063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Linear\n",
      "30\n",
      "0.7692307692307693\n",
      "wp= [[-0.76299101  1.13822047  0.62477054]\n",
      " [ 0.6014925  -0.88680328  0.28531078]\n",
      " [ 0.59784609 -0.10575032 -0.49209577]\n",
      " [-0.85299054  2.07290305 -1.2199125 ]\n",
      " [ 0.14176955 -3.06489748  2.92312792]\n",
      " [-0.01193797  0.23828328 -0.22634531]\n",
      " [-0.12685437 -0.44906348  0.57591784]\n",
      " [-0.0345378  -0.02301658  0.05755437]\n",
      " [ 0.0405222  -0.19925454  0.15873235]\n",
      " [ 0.00558587  0.31463436 -0.32022024]\n",
      " [ 0.09555557 -0.10296338  0.00740781]\n",
      " [-0.14809056  1.04541241 -0.89732185]\n",
      " [ 0.0906437  -0.37729444  0.28665074]\n",
      " [-0.07777166  1.0010156  -0.92324394]\n",
      " [ 0.12824961 -1.27034815  1.14209854]]\n",
      "For Polynomial\n",
      "38\n",
      "0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv \n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "# print(iris_dataset.data)\n",
    "\n",
    "## (a) split data \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split( iris_dataset['data'], iris_dataset['target'], test_size=0.26, random_state=0) \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "onehot_encoder=OneHotEncoder(sparse=False) # Use sparse_output instead of sparse for the new version\n",
    "reshaped = y_train.reshape(len(y_train), 1) \n",
    "Ytr_onehot = onehot_encoder.fit_transform(reshaped) \n",
    "\n",
    "## (c) Linear Classification \n",
    "bias1 = np.ones((X_train.shape[0], 1)) \n",
    "X_train_b = np.concatenate((bias1, X_train), axis = 1) \n",
    "w = inv(X_train_b.T @ X_train_b) @ X_train_b.T @ Ytr_onehot \n",
    "# print(w) \n",
    "\n",
    "# calculate the output based on the estimated w and test input X and then assign to one of the classes based on one hot encoding \n",
    "Bias2 = np.ones((X_test.shape[0], 1)) \n",
    "X_test_p = np.concatenate((Bias2, X_test), axis = 1) \n",
    "yt_est = X_test_p.dot(w); \n",
    "yt_cls = [[1 if y == max(x) else 0 for y in x] for x in yt_est ] \n",
    "# print(yt_cls) \n",
    "\n",
    "# compare the predicted y with the ground truth \n",
    "reshaped = y_test.reshape(len(y_test), 1) \n",
    "Yts_onehot = onehot_encoder.fit_transform(reshaped)\n",
    "m1 = np.matrix(Yts_onehot) \n",
    "m2 = np.matrix(yt_cls) \n",
    "difference = np.abs(m1 - m2) \n",
    "# print(difference) \n",
    "\n",
    "# calculate the error rate/accuracy \n",
    "correct = np.where(~difference.any(axis=1))[0] \n",
    "accuracy = len(correct)/len(difference) \n",
    "print(\"For Linear\")\n",
    "print(len(correct)) \n",
    "print(accuracy)\n",
    "\n",
    "## (d) Polynomial Classification \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "poly = PolynomialFeatures(2) \n",
    "P = poly.fit_transform(X_train) \n",
    "Pt = poly.fit_transform(X_test) \n",
    "\n",
    "if P.shape[0] > P.shape[1]: \n",
    "    wp = inv(P.T @ P) @ P.T @ Ytr_onehot\n",
    "else: \n",
    "    wp = P.T @ inv(P @ P.T) @ Ytr_onehot \n",
    "\n",
    "print(\"wp=\", wp) \n",
    "\n",
    "yt_est_p = Pt@wp; \n",
    "yt_cls_p = [[1 if y == max(x) else 0 for y in x] for x in yt_est_p ] \n",
    "# print(yt_cls_p) \n",
    "\n",
    "m1 = np.matrix(Yts_onehot) \n",
    "m2 = np.matrix(yt_cls_p) \n",
    "difference = np.abs(m1 - m2) \n",
    "# print(difference) \n",
    "\n",
    "correct_p = np.where(~difference.any(axis=1))[0] \n",
    "accuracy_p = len(correct_p)/len(difference) \n",
    "print(\"For Polynomial\")\n",
    "print(len(correct_p)) \n",
    "print(accuracy_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b65d90-ae35-488a-85ab-eb3e8f4cfa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yt_est_p\n",
      "[[ 4.39804651e+12  2.19902326e+12  4.39804651e+12]\n",
      " [ 2.19902326e+12 -1.09951163e+12  3.29853488e+12]\n",
      " [ 4.39804651e+12  3.29853488e+12  6.59706977e+12]\n",
      " [ 3.29853488e+12  5.19943718e-01  3.29853488e+12]\n",
      " [ 5.49755814e+12  3.29853488e+12  5.49755814e+12]\n",
      " [ 5.49755814e+12  3.29853488e+12  5.49755814e+12]\n",
      " [ 5.49755814e+12  3.29853488e+12  5.49755814e+12]\n",
      " [ 3.29853488e+12  2.19902326e+12  3.29853488e+12]\n",
      " [ 1.09951163e+12  1.09951163e+12  3.29853488e+12]\n",
      " [ 3.29853488e+12  1.09951163e+12  5.49755814e+12]\n",
      " [ 2.19902326e+12  2.19902326e+12  6.59706977e+12]\n",
      " [ 4.39804651e+12  2.19902326e+12  3.29853488e+12]\n",
      " [ 4.39804651e+12  3.29853488e+12  6.59706977e+12]\n",
      " [ 3.29853488e+12  1.09951163e+12  4.39804651e+12]\n",
      " [ 3.29853488e+12  3.29853488e+12  5.49755814e+12]\n",
      " [ 4.39804651e+12  3.29853488e+12  7.69658139e+12]\n",
      " [ 4.39804651e+12  2.19902326e+12  4.39804651e+12]\n",
      " [ 4.39804651e+12  2.19902326e+12  5.49755814e+12]\n",
      " [ 4.39804651e+12  4.39804651e+12  5.49755814e+12]\n",
      " [ 3.29853488e+12  1.09951163e+12  5.49755814e+12]\n",
      " [ 5.49755814e+12  4.39804651e+12  5.49755814e+12]\n",
      " [ 5.49755814e+12  5.49755814e+12  6.59706977e+12]\n",
      " [ 5.49755814e+12  4.39804651e+12  6.59706977e+12]\n",
      " [ 5.49755814e+12  3.29853488e+12  6.59706977e+12]\n",
      " [ 3.29853488e+12  2.19902326e+12  4.39804651e+12]\n",
      " [ 4.39804651e+12  3.29853488e+12  6.59706977e+12]\n",
      " [ 5.49755814e+12  3.29853488e+12  6.59706977e+12]\n",
      " [ 3.29853488e+12  1.09951163e+12  3.29853488e+12]\n",
      " [ 4.39804651e+12  2.19902326e+12  3.29853488e+12]\n",
      " [ 5.49755814e+12  2.19902326e+12  5.49755814e+12]\n",
      " [ 5.49755814e+12  1.09951163e+12  4.39804651e+12]\n",
      " [ 5.49755814e+12  4.39804651e+12  6.59706977e+12]\n",
      " [ 4.39804651e+12  2.19902326e+12  5.49755814e+12]\n",
      " [ 4.39804651e+12  4.39804651e+12  5.49755814e+12]\n",
      " [ 3.29853488e+12  7.76706048e-01  3.29853488e+12]\n",
      " [ 3.29853488e+12  3.29853488e+12  6.59706977e+12]\n",
      " [ 4.39804651e+12  1.09951163e+12  5.49755814e+12]\n",
      " [ 2.19902326e+12  1.09951163e+12  5.49755814e+12]\n",
      " [ 4.39804651e+12  3.29853488e+12  5.49755814e+12]]\n"
     ]
    }
   ],
   "source": [
    "print(\"yt_est_p\")\n",
    "print(yt_est_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8638184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yt_cls_p\n",
      "[[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"yt_cls_p\")\n",
    "print(yt_cls_p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "794bcebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484c5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d1183b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
