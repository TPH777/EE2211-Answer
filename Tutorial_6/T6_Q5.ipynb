{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0fc9d8-b047-4a4c-aa4d-ad74ad9d5eda",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">  Tutorial 6, Question 5: </span>\n",
    "\n",
    "Given the training data:\n",
    "{𝑥 = −1} → { 𝑦 = 𝑐𝑙𝑎𝑠𝑠1 }\n",
    "{𝑥 = 0 } → { 𝑦 = 𝑐𝑙𝑎𝑠𝑠1 }\n",
    "{𝑥 = 0.5} → { 𝑦 = 𝑐𝑙𝑎𝑠𝑠2 }\n",
    "{𝑥 = 0.3} → { 𝑦 = 𝑐𝑙𝑎𝑠𝑠3 }\n",
    "{𝑥 = 0.8} → { 𝑦 = 𝑐𝑙𝑎𝑠𝑠2 }\n",
    "\n",
    "1. Predict the class label for {𝑥 = −0.1} and {𝑥 = 0.4} based on linear regression towards a one-hot encoded\n",
    "target.\n",
    "2. Predict the class label for {𝑥 = −0.1} and {𝑥 = 0.4} using a polynomial model of 5th order and a one-hot\n",
    "encoded target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc10f40f-9328-46d0-a987-00d4c84cd62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[ 0.07441524  1.53840883 -0.61282406]\n",
      " [ 0.10300392 -0.0500674  -0.05293652]\n",
      " [ 0.21274711 -0.40080364  0.18805654]\n",
      " [-0.2510306   0.23622893  0.01480167]\n",
      " [-0.0365881  -0.50708077  0.54366887]]\n",
      "[[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]]\n",
      "30\n",
      "0.7692307692307693\n",
      "[[-7.54136394e+27 -7.19836175e+27 -9.13051549e+27]\n",
      " [ 7.54136394e+27  7.19836175e+27  9.13051549e+27]\n",
      " [-9.33213312e+12 -4.40987378e+12 -1.18024447e+13]\n",
      " [-1.58552030e+12  1.77985987e+13 -4.11651834e+12]\n",
      " [ 4.41834796e+11  1.00159346e+13  1.31655049e+12]\n",
      " [ 3.23083012e+14  2.65042539e+14  3.94965206e+14]\n",
      " [-7.89207971e+14 -6.18628720e+14 -9.86879925e+14]\n",
      " [ 6.78945879e+12  1.72551922e+12  8.43175437e+12]\n",
      " [ 3.40830442e+12 -1.58916332e+13  7.00960831e+12]\n",
      " [ 6.70991231e+11 -8.73818187e+12  4.76168861e+11]\n",
      " [-3.23418019e+14 -2.65652425e+14 -3.96133437e+14]\n",
      " [ 6.50847845e-01 -1.41380238e+00  1.72604590e+00]\n",
      " [ 7.75906246e-01  3.04429973e+00  6.27631824e-01]\n",
      " [-4.30119549e-01  8.12986129e-01 -1.12808460e+00]\n",
      " [ 1.22292336e+00  2.27391368e+00  1.58811632e+00]\n",
      " [ 3.29518308e-01 -1.99847307e+00  1.31420368e+00]\n",
      " [-2.94275637e-02  2.97225615e-01 -6.95429180e-03]\n",
      " [ 1.30240456e-01 -3.50825599e+00  7.56473339e-01]\n",
      " [ 4.63980926e-03 -2.18813902e-01  7.64651008e-02]\n",
      " [ 5.60787897e-02 -6.37354018e-01 -8.06508752e-02]\n",
      " [ 3.11898677e-03  1.60476456e-01  3.34043561e-01]]\n",
      "[[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1]]\n",
      "[[0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]]\n",
      "8\n",
      "0.20512820512820512\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import inv \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "X = np.array([[1,-1], [1,0], [1,0.5], [1,0.3], [1,0.8]]) \n",
    "Y = np.array([[1,0,0], [1,0,0], [0,1,0], [0,0,1], [0,1,0]]) \n",
    "\n",
    "## Linear regression for classification \n",
    "W = inv(X.T @ X) @ X.T @ Y \n",
    "print(W) \n",
    "\n",
    "Xt = np.array([[1,-0.1], [1,0.4]]) \n",
    "y_predict = Xt @ W \n",
    "print(y_predict) \n",
    "y_class_predict = [[1 if y == max(x) else 0 for y in x] for x in y_predict ] \n",
    "print(y_class_predict) \n",
    "\n",
    "## Polynomial regression for \n",
    "## Generate polynomial features \n",
    "order = 5 \n",
    "poly = PolynomialFeatures(order) \n",
    "\n",
    "## only the data column (2nd) is needed for generation of polynomial terms \n",
    "reshaped = X[:,1].reshape(len(X[:,1]),1) \n",
    "P = poly.fit_transform(reshaped) \n",
    "reshaped = Xt[:,1].reshape(len(Xt[:,1]),1) \n",
    "Pt = poly.fit_transform(reshaped) \n",
    "\n",
    "## dual solution (without ridge) \n",
    "Wp_dual = P.T @ inv(P @ P.T) @ Y \n",
    "print(Wp_dual) \n",
    "\n",
    "yp_predict = Pt @ Wp_dual \n",
    "print(yp_predict) \n",
    "yp_class_predict = [[1 if y == max(x) else 0 for y in x] for x in yp_predict ] \n",
    "\n",
    "print(yp_class_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852bf57-deef-4a7b-8890-b0d6225e3b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
