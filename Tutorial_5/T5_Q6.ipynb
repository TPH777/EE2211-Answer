{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d7760c-b1cb-4eb3-b888-8c6feeb20bf3",
   "metadata": {},
   "source": [
    "## Tutorial 5 Question 6\n",
    "Download the CSV file for red-wine using “ wine = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learningdatabases/\n",
    "wine-quality/winequality-red.csv\",sep=';') ” . Use Python to perform the following tasks. Hint: use Python\n",
    "packages like numpy, pandas, matplotlib.pyplot, numpy.linalg, and sklearn.metrics.\n",
    "1. Take y = wine.quality as the target output and x = wine.drop('quality',axis = 1)as the input features. Assume the given list of data is already randomly indexed (i.e., not in particular order), split the database into two sets: [0:1500] samples for regression training, and [1500:1599] samples for testing.\n",
    "2. Perform linear regression on the training set and print out the learned parameters.\n",
    "3. Perform prediction using the test set and provide the prediction accuracy in terms of the mean of squared\n",
    "errors (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "459ce4dc-db90-42d7-9881-b584c7cfa9c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "[ 2.22330327e+01  2.68702621e-02 -1.12838019e+00 -2.06141685e-01\n",
      "  1.22000584e-02 -1.77718503e+00  4.29357454e-03 -3.18953315e-03\n",
      " -1.81795124e+01 -3.98142390e-01  8.92474793e-01  2.77147239e-01]\n",
      "0.34352638121356655\n",
      "0.34352638121356655\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "## get data from web\n",
    "# wine = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/winequality/winequality-red.csv\",sep=';')\n",
    "wine = pd.read_csv(\"winequality-red.csv\",sep=';'); # get data from the downloaded local file\n",
    "wine.info()\n",
    "y = wine.quality\n",
    "x = wine.drop('quality',axis = 1)\n",
    "\n",
    "## Include the offset/bias term\n",
    "x0 = np.ones((len(y),1))\n",
    "X = np.hstack((x0,x))\n",
    "## split data into training and test sets\n",
    "## (Note: this exercise introduces the basic protocol of using the training-test \n",
    "## partitioning of samples for evaluation assuming the list of data is already randomly indexed)\n",
    "## In case you really want a general random split to have a better training/test distributions:\n",
    "## from sklearn.model_selection import train_test_split\n",
    "## train_X,test_X,train_y,test_y = train_test_split(X,y,test_size=99/1599, random_state = 0)\n",
    "train_X = X[0:1500]\n",
    "train_y = y[0:1500]\n",
    "test_X = X[1500:1599]\n",
    "test_y = y[1500:1599]\n",
    "\n",
    "## linear regression\n",
    "w = inv(train_X.T @ train_X) @ train_X.T @ train_y\n",
    "print(w)\n",
    "yt_est = test_X.dot(w);\n",
    "MSE = np.square(np.subtract(test_y,yt_est)).mean()\n",
    "print(MSE)\n",
    "MSE = mean_squared_error(test_y,yt_est)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d9d9c-295c-42bc-8b4f-ce98c0c97abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
